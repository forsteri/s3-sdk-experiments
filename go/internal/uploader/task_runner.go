package uploader

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"time"

	"s3-uploader/internal/aws"
	"s3-uploader/internal/logger"
	"s3-uploader/internal/models"
)

// TaskRunner ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œã‚’ç®¡ç†ã™ã‚‹æ§‹é€ ä½“
type TaskRunner struct {
	uploader *Uploader
	config   models.Config
	logger   *logger.Logger
}

// NewTaskRunner æ–°ã—ã„TaskRunnerã‚’ä½œæˆ
func NewTaskRunner(client aws.S3Operations, config models.Config) *TaskRunner {
	lgr := logger.GetLogger()
	uploader := NewUploader(client, config.Options)
	
	return &TaskRunner{
		uploader: uploader,
		config:   config,
		logger:   lgr,
	}
}

// TaskResult ã‚¿ã‚¹ã‚¯å®Ÿè¡Œçµæœ
type TaskResult struct {
	TaskName      string
	StartTime     time.Time
	EndTime       time.Time
	Duration      time.Duration
	TotalFiles    int
	SuccessFiles  int
	FailedFiles   int
	SkippedFiles  int
	TotalBytes    int64
	UploadResults []UploadResult
	Error         error
}

// RunReport å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
type RunReport struct {
	StartTime    time.Time
	EndTime      time.Time
	Duration     time.Duration
	TotalTasks   int
	SuccessTasks int
	FailedTasks  int
	SkippedTasks int
	TaskResults  []TaskResult
	DryRun       bool
}

// RunAllTasks ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
func (tr *TaskRunner) RunAllTasks(ctx context.Context) (*RunReport, error) {
	report := &RunReport{
		StartTime:   time.Now(),
		DryRun:      tr.config.Options.DryRun,
		TaskResults: make([]TaskResult, 0),
	}

	if tr.config.Options.DryRun {
		tr.logger.Info("ğŸƒ Running in DRY RUN mode - no files will be uploaded")
	}

	tr.logger.Info("Starting task runner",
		"total_tasks", len(tr.config.UploadTasks),
		"dry_run", tr.config.Options.DryRun,
	)

	// å„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
	for _, task := range tr.config.UploadTasks {
		// ã‚¿ã‚¹ã‚¯ãŒç„¡åŠ¹ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
		if !task.Enabled {
			tr.logger.Info("Skipping disabled task", "task", task.Name)
			report.SkippedTasks++
			continue
		}

		tr.logger.Info("ğŸ“‹ Starting task",
			"name", task.Name,
			"description", task.Description,
		)

		result := tr.runTask(ctx, task)
		report.TaskResults = append(report.TaskResults, result)

		if result.Error != nil {
			report.FailedTasks++
			tr.logger.Error("âŒ Task failed",
				"task", task.Name,
				"error", result.Error,
			)
		} else {
			report.SuccessTasks++
			tr.logger.Info("âœ… Task completed",
				"task", task.Name,
				"duration", result.Duration,
				"files", result.SuccessFiles,
				"bytes", result.TotalBytes,
			)
		}
	}

	report.EndTime = time.Now()
	report.Duration = report.EndTime.Sub(report.StartTime)
	report.TotalTasks = len(tr.config.UploadTasks)

	return report, nil
}

// runTask å€‹åˆ¥ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ
func (tr *TaskRunner) runTask(ctx context.Context, task models.UploadTask) TaskResult {
	result := TaskResult{
		TaskName:  task.Name,
		StartTime: time.Now(),
	}

	// ã‚½ãƒ¼ã‚¹ã®å­˜åœ¨ç¢ºèª
	sourceInfo, err := os.Stat(task.Source)
	if err != nil {
		result.Error = fmt.Errorf("source not found: %w", err)
		result.EndTime = time.Now()
		result.Duration = result.EndTime.Sub(result.StartTime)
		return result
	}

	// ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã§å‡¦ç†ã‚’åˆ†å²
	if sourceInfo.IsDir() {
		// ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
		recursive := task.Recursive // Recursiveã¯ç›´æ¥boolå‹

		// S3ã‚­ãƒ¼ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’æ±ºå®š
		keyPrefix := ""
		if task.S3KeyPrefix != nil {
			keyPrefix = *task.S3KeyPrefix
		}

		tr.logger.Debug("Uploading directory",
			"source", task.Source,
			"bucket", task.Bucket,
			"prefix", keyPrefix,
			"recursive", recursive,
		)

		// ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã‚’ä½¿ã£ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
		uploadResults, err := tr.uploader.UploadDirectoryWithRetry(ctx, task.Source, task.Bucket, keyPrefix, recursive)
		result.UploadResults = uploadResults
		result.Error = err

		// çµæœã‚’é›†è¨ˆ
		for _, ur := range uploadResults {
			result.TotalFiles++
			if ur.Success {
				if ur.SkippedReason != "" {
					result.SkippedFiles++
				} else {
					result.SuccessFiles++
					result.TotalBytes += ur.Size
				}
			} else {
				result.FailedFiles++
			}
		}
	} else {
		// å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
		var key string
		if task.S3Key != nil && *task.S3Key != "" {
			key = *task.S3Key
		} else {
			// S3ã‚­ãƒ¼ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½¿ç”¨
			key = filepath.Base(task.Source)
		}

		tr.logger.Debug("Uploading file",
			"source", task.Source,
			"bucket", task.Bucket,
			"key", key,
		)

		// ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã‚’ä½¿ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
		uploadResult, err := tr.uploader.UploadFileWithRetry(ctx, task.Source, task.Bucket, key)
		result.UploadResults = []UploadResult{*uploadResult}
		result.Error = err
		result.TotalFiles = 1

		if uploadResult.Success {
			if uploadResult.SkippedReason != "" {
				result.SkippedFiles = 1
			} else {
				result.SuccessFiles = 1
				result.TotalBytes = uploadResult.Size
			}
		} else {
			result.FailedFiles = 1
		}
	}

	result.EndTime = time.Now()
	result.Duration = result.EndTime.Sub(result.StartTime)

	return result
}

// PrintReport ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›
func (tr *TaskRunner) PrintReport(report *RunReport) {
	fmt.Println("\n" + strings.Repeat("=", 60))
	fmt.Println("ğŸ“Š UPLOAD TASK RUNNER REPORT")
	fmt.Println(strings.Repeat("=", 60))

	if report.DryRun {
		fmt.Println("ğŸƒ Mode: DRY RUN (no files were actually uploaded)")
	} else {
		fmt.Println("ğŸƒ Mode: LIVE")
	}

	fmt.Printf("â±ï¸  Total Duration: %s\n", report.Duration.Round(time.Millisecond))
	fmt.Printf("ğŸ“… Start Time: %s\n", report.StartTime.Format("2006-01-02 15:04:05"))
	fmt.Printf("ğŸ“… End Time: %s\n", report.EndTime.Format("2006-01-02 15:04:05"))
	fmt.Println()

	// ã‚¿ã‚¹ã‚¯ã‚µãƒãƒªãƒ¼
	fmt.Println("ğŸ“‹ Task Summary:")
	fmt.Printf("   Total Tasks: %d\n", report.TotalTasks)
	fmt.Printf("   âœ… Successful: %d\n", report.SuccessTasks)
	fmt.Printf("   âŒ Failed: %d\n", report.FailedTasks)
	fmt.Printf("   â­ï¸  Skipped: %d\n", report.SkippedTasks)
	fmt.Println()

	// å„ã‚¿ã‚¹ã‚¯ã®è©³ç´°
	fmt.Println("ğŸ“ Task Details:")
	for i, task := range report.TaskResults {
		fmt.Printf("\n%d. %s\n", i+1, task.TaskName)
		fmt.Printf("   Duration: %s\n", task.Duration.Round(time.Millisecond))
		fmt.Printf("   Files: %d total (%d success, %d failed, %d skipped)\n",
			task.TotalFiles, task.SuccessFiles, task.FailedFiles, task.SkippedFiles)
		fmt.Printf("   Total Size: %s\n", formatBytes(task.TotalBytes))

		if task.Error != nil {
			fmt.Printf("   âŒ Error: %v\n", task.Error)
		}

		// å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°ï¼ˆæœ€å¤§5ä»¶ï¼‰
		if task.FailedFiles > 0 {
			fmt.Println("   Failed Files:")
			count := 0
			for _, ur := range task.UploadResults {
				if !ur.Success && ur.Error != nil {
					fmt.Printf("     - %s: %v\n", ur.Source, ur.Error)
					count++
					if count >= 5 && task.FailedFiles > 5 {
						fmt.Printf("     ... and %d more\n", task.FailedFiles-5)
						break
					}
				}
			}
		}
	}

	fmt.Println("\n" + strings.Repeat("=", 60))
}

// formatBytes ãƒã‚¤ãƒˆæ•°ã‚’äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
func formatBytes(bytes int64) string {
	const (
		KB = 1024
		MB = KB * 1024
		GB = MB * 1024
	)

	switch {
	case bytes >= GB:
		return fmt.Sprintf("%.2f GB", float64(bytes)/GB)
	case bytes >= MB:
		return fmt.Sprintf("%.2f MB", float64(bytes)/MB)
	case bytes >= KB:
		return fmt.Sprintf("%.2f KB", float64(bytes)/KB)
	default:
		return fmt.Sprintf("%d B", bytes)
	}
}
